---
kind: ConfigMap
apiVersion: v1
data:
  net.input.conf: |-
    # Example
    # '{"time":"2016-02-17T00:04:05.931087621Z", "labels": {"app": "test", "version": 3} ,"log": {"level": "info", "message": "Some log text here"}}'
    <source>
      @type tcp
      tag net.tcp
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
      source_hostname_key client_host
      source_address_key client_addr
      port {{ .Values.fluentd.tcpPort }}
    </source>

    <source>
      @type udp
      tag net.udp
      <parse>
        @type json
        time_key time
        time_format %Y-%m-%dT%H:%M:%S.%NZ
      </parse>
      source_hostname_key client_host
      source_address_key client_addr
      port {{ .Values.fluentd.udpPort }}
    </source>
  containers.input.conf: |-
    # Example:
    # {"log":"[info:2016-02-16T16:04:05.930-08:00] Some log text here\n","stream":"stdout","time":"2016-02-17T00:04:05.931087621Z"}
    <source>
      @type tail
      path /var/log/containers/*.log
      pos_file /var/log/containers.log.pos
      time_format %Y-%m-%dT%H:%M:%S.%NZ
      tag kubernetes.*
      format json
      keep_time_key true
      read_from_head true
    </source>
  system.input.conf: |-
    # Logs from systemd-journal for interesting services.
    <source>
      @type systemd
      matches [{ "_SYSTEMD_UNIT": "docker.service" }]
      read_from_head true
      tag docker
    </source>

    <source>
      @type systemd
      matches [{ "_SYSTEMD_UNIT": "kubelet.service" }]
      read_from_head true
      tag kubelet
    </source>
  forward.input.conf: |-
    # Takes the messages sent over TCP
    <source>
      @type forward
      port {{ .Values.fluentd.forwardPort }}
    </source>
{{- if .Values.fluentd.prometheusEnabled }}
  monitoring.conf: |-
    # Prometheus Exporter Plugin
    # input plugin that exports metrics
    <source>
      @type prometheus
      bind 0.0.0.0
      port {{ .Values.fluentd.exporterPort }}
      metrics_path /metrics
    </source>

    <source>
      @type monitor_agent
    </source>

    # input plugin that collects metrics from MonitorAgent
    <source>
      @type prometheus_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>

    # input plugin that collects metrics for output plugin
    <source>
      @type prometheus_output_monitor
      <labels>
        host ${hostname}
      </labels>
    </source>

    # input plugin that collects metrics for in_tail plugin
    # This section disabled due to metrics count - tail plugin
    # generate too many metrics
    #<source>
    #  @type prometheus_tail_monitor
    #  <labels>
    #    host ${hostname}
    #  </labels>
    #</source>
{{- end }}
  output.conf: |-
    # Enriches records with Kubernetes metadata
    <filter kubernetes.**>
      @type kubernetes_metadata
      cache_size 100000
      cache_ttl 3600
      # Watch api disabled due to implementation problems
      # https://github.com/fabric8io/fluent-plugin-kubernetes_metadata_filter/issues/88#issuecomment-514433183
      watch false
    </filter>

    <filter kubernetes.**>
      @type record_modifier
      <record>
        _json_log_             ${ log = record["log"].strip; if log[0].eql?('{') && log[-1].eql?('}'); begin; JSON.parse(log); rescue JSON::ParserError; end; end }
        timestamp              ${time}
        nsec                   ${record["time"].split('.').last.to_i}
        # static fields
        source                 "kubernetes"
        namespace              ${record["kubernetes"]["namespace_name"]}
        host                   ${record["kubernetes"]["host"] || ENV["K8S_NODE_NAME"]}
        pod_name               ${record["kubernetes"]["pod_name"]}
        container_name         ${record["kubernetes"]["container_name"]}
        stream                 ${record["stream"]}
        # dynamic fields
        labels.names           ${record["kubernetes"].key?("labels") ? record["kubernetes"]["labels"].keys : []}
        labels.values          ${record["kubernetes"].key?("labels") ? record["kubernetes"]["labels"].values : []}
        string_fields.names    ${record["_json_log_"] ? record["_json_log_"].select{|_, v| !v.nil? && !v.is_a?(Numeric) && !v.is_a?(TrueClass) && !v.is_a?(FalseClass)}.keys : ["log"]}
        string_fields.values   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| !v.nil? && !v.is_a?(Numeric) && !v.is_a?(TrueClass) && !v.is_a?(FalseClass)}.values.map(&:to_s) : [record["log"]]}

        number_fields.names    ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(Numeric)}.keys : []}
        number_fields.values   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(Numeric)}.values : []}

        boolean_fields.names   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(TrueClass) || v.is_a?(FalseClass)}.keys : []}
        boolean_fields.values  ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(TrueClass) || v.is_a?(FalseClass)}.values.map{|v| v ? 1 : 0} : []}

        null_fields.names      ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.nil?}.keys : []}
      </record>
      remove_keys kubernetes, docker, master_url, time, log, _json_log_
    </filter>

    <filter net.**>
      @type record_modifier
      <record>
        _json_log_             ${ log = record["log"]; if log.is_a?(Hash); begin; log; rescue JSON::ParserError; end; end }
        _labels_               ${ if record.key?("labels"); labels = record["labels"]; if labels.is_a?(Hash); begin; labels; rescue JSON::ParserError; end; end; end }
        timestamp              ${time}
        # static fields
        source                 "net"
        namespace              {{ printf "%s" .Release.Namespace | quote }}
        host                   ${record["client_addr"]}
        pod_name               ${record["client_host"]}
        container_name         "net"
        stream                 "net"
        # dynamic fields
        labels.names           ${record["_labels_"] ? record["_labels_"].keys.map(&:to_s) : []}
        labels.values          ${record["_labels_"] ? record["_labels_"].values.map(&:to_s) : []}
        string_fields.names    ${record["_json_log_"] ? record["_json_log_"].select{|_, v| !v.nil? && !v.is_a?(Numeric) && !v.is_a?(TrueClass) && !v.is_a?(FalseClass)}.keys : ["log"]}
        string_fields.values   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| !v.nil? && !v.is_a?(Numeric) && !v.is_a?(TrueClass) && !v.is_a?(FalseClass)}.values.map(&:to_s) : [record["log"]]}

        number_fields.names    ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(Numeric)}.keys : []}
        number_fields.values   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(Numeric)}.values : []}

        boolean_fields.names   ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(TrueClass) || v.is_a?(FalseClass)}.keys : []}
        boolean_fields.values  ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.is_a?(TrueClass) || v.is_a?(FalseClass)}.values.map{|v| v ? 1 : 0} : []}

        null_fields.names      ${record["_json_log_"] ? record["_json_log_"].select{|_, v| v.nil?}.keys : []}
      </record>
      remove_keys time, log, _json_log_, client_addr, client_host, _labels_, labels
    </filter>

    <filter docker.**>
      @type record_modifier
      <record>
        timestamp              ${time}
        source                 "docker"
        host                   ${record["_HOSTNAME"]}
        stream                 ${record["_TRANSPORT"]}
        string_fields.names    ${["log"]}
        string_fields.values   ${[record["MESSAGE"]]}
      </record>
      remove_keys _TRANSPORT, PRIORITY, SYSLOG_FACILITY, _UID, _GID, _CAP_EFFECTIVE, _SYSTEMD_SLICE, _BOOT_ID, _MACHINE_ID, _HOSTNAME, SYSLOG_IDENTIFIER, _PID, _COMM, _EXE, _CMDLINE, _SYSTEMD_CGROUP, _SYSTEMD_UNIT, MESSAGE
    </filter>

    <filter kubelet.**>
      @type record_modifier
      <record>
        timestamp              ${time}
        source                 "kubelet"
        host                   ${record["_HOSTNAME"]}
        stream                 ${record["_TRANSPORT"]}
        string_fields.names    ${["log"]}
        string_fields.values   ${[record["MESSAGE"]]}
      </record>
      remove_keys _TRANSPORT, PRIORITY, SYSLOG_FACILITY, _UID, _GID, _CAP_EFFECTIVE, _SYSTEMD_SLICE, _BOOT_ID, _MACHINE_ID, _HOSTNAME, SYSLOG_IDENTIFIER, _PID, _COMM, _EXE, _CMDLINE, _SYSTEMD_CGROUP, _SYSTEMD_UNIT, MESSAGE
    </filter>

    <filter **>
      @type record_modifier
      whitelist_keys timestamp, nsec, source, namespace, host, pod_name, container_name, stream, labels.names, labels.values, string_fields.names, string_fields.values, number_fields.names, number_fields.values, boolean_fields.names, boolean_fields.values, null_fields.names
    </filter>

    <match **>
      @type exec
      @id load2clickhouse
      command bash /usr/local/bin/insert_ch.sh {{ template "fluentdInsertTable" $ }}
      format json
      <buffer>
        @type memory
        chunk_limit_size 64m
        queue_limit_length 32
        flush_at_shutdown true
        flush_interval 15s
        flush_thread_count 4
      </buffer>
    </match>
metadata:
  name: fluentd-config
  namespace: {{ .Release.Namespace }}
  labels:
    addonmanager.kubernetes.io/mode: Reconcile

